{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathing 2: Pysyft and Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Federated Learning Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]])\n",
    "target = torch.tensor([[0],[0],[1],[1.]])\n",
    "\n",
    "# A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "def train():\n",
    "    # Training Logic\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(20):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        pred = model(data)\n",
    "\n",
    "        # 3) calculate how much we missed\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) change those weights\n",
    "        opt.step()\n",
    "\n",
    "        # 6) print our progress\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8703)\n",
      "tensor(1.0659)\n",
      "tensor(0.6785)\n",
      "tensor(0.4755)\n",
      "tensor(0.3393)\n",
      "tensor(0.2441)\n",
      "tensor(0.1768)\n",
      "tensor(0.1289)\n",
      "tensor(0.0946)\n",
      "tensor(0.0698)\n",
      "tensor(0.0517)\n",
      "tensor(0.0385)\n",
      "tensor(0.0288)\n",
      "tensor(0.0216)\n",
      "tensor(0.0162)\n",
      "tensor(0.0122)\n",
      "tensor(0.0092)\n",
      "tensor(0.0070)\n",
      "tensor(0.0053)\n",
      "tensor(0.0040)\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've trained a basic model in the normal way - now we must train it in a federated way!\n",
    "# This is a multi step process\n",
    "# 1. Create a couple workers\n",
    "# 2. Get pointers to training data on each worker\n",
    "# 3. Updated training logic to do federated learning\n",
    "# Training Steps:\n",
    "# 1. Send model to correct worker\n",
    "# 2. Train on the data located there\n",
    "# 3. Get the model back and repeat with next worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "jake = sy.VirtualWorker(hook, id=\"jake\")\n",
    "toby = sy.VirtualWorker(hook, id=\"toby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to jake and toby\n",
    "data_jake = data[0:2]\n",
    "target_jake = target[0:2]\n",
    "\n",
    "data_toby = data[2:]\n",
    "target_toby = target[2:]\n",
    "\n",
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "data_jake = data_jake.send(jake)\n",
    "data_toby = data_toby.send(toby)\n",
    "target_jake = target_jake.send(jake)\n",
    "target_toby = target_toby.send(toby)\n",
    "\n",
    "# organize pointers into a list\n",
    "datasets = [(data_jake,target_jake),(data_toby,target_toby)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.federated.floptimizer import Optims\n",
    "workers = ['jake', 'toby']\n",
    "optims = Optims(workers, optim=optim.Adam(params=model.parameters(),lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Training Logic\n",
    "    for iter in range(10):\n",
    "        \n",
    "        # NEW) iterate through each worker's dataset\n",
    "        for data,target in datasets:\n",
    "            \n",
    "            # NEW) send model to correct worker\n",
    "            model.send(data.location)\n",
    "            \n",
    "            #Call the optimizer for the worker using get_optim\n",
    "            opt = optims.get_optim(data.location.id)\n",
    "            #print(data.location.id)\n",
    "\n",
    "            # 1) erase previous gradients (if they exist)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # 2) make a prediction\n",
    "            pred = model(data)\n",
    "\n",
    "            # 3) calculate how much we missed\n",
    "            loss = ((pred - target)**2).sum()\n",
    "\n",
    "            # 4) figure out which weights caused us to miss\n",
    "            loss.backward()\n",
    "\n",
    "            # 5) change those weights\n",
    "            opt.step()\n",
    "            \n",
    "            # NEW) get model (with gradients)\n",
    "            model.get()\n",
    "\n",
    "            # 6) print our progress\n",
    "            print(loss.get().data) # NEW) slight edit... need to call .get() on loss\\\n",
    "    \n",
    "# federated averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4928)\n",
      "tensor(2.7715)\n",
      "tensor(0.1333)\n",
      "tensor(1.3551)\n",
      "tensor(0.1435)\n",
      "tensor(0.6209)\n",
      "tensor(0.3279)\n",
      "tensor(0.3036)\n",
      "tensor(0.4963)\n",
      "tensor(0.1868)\n",
      "tensor(0.5739)\n",
      "tensor(0.1468)\n",
      "tensor(0.5562)\n",
      "tensor(0.1228)\n",
      "tensor(0.4679)\n",
      "tensor(0.0933)\n",
      "tensor(0.3429)\n",
      "tensor(0.0592)\n",
      "tensor(0.2141)\n",
      "tensor(0.0305)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortcomings of this application -> we call model.get() and recieve the updated model from Toby or Jake,\n",
    "#we learn alot about Jake & Toby by looking at their gradients\n",
    "#sometimes can perfectly restore their training data\n",
    "#Strategies?\n",
    "#1. Average the gradient across multiple individuals bf uploading to central server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Remote Execution Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to average the gradients before calling .get() so we don't ever see anyone's exact gradient.\n",
    "\n",
    "To do this must:\n",
    "- use a pointer to send a Tensor directly to another worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jake = sy.VirtualWorker(hook, id='jake')\n",
    "toby = sy.VirtualWorker(hook, id='toby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:toby #objects:0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jake.clear_objects()\n",
    "toby.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a local tensor\n",
    "x = torch.tensor([1,2,3,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:47705114154 -> jake:35365737396]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this sends the local tensor to Jake\n",
    "x_ptr = x.send(jake)\n",
    "\n",
    "# this is now a pointer\n",
    "x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:50971181403 -> toby:47705114154]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can SEND THE POINTER to toby!!!\n",
    "pointer_to_x_ptr = x_ptr.send(toby)\n",
    "\n",
    "pointer_to_x_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a tensor called x and sent it to Jake, creating a pointer on our local machine (x_ptr)\n",
    "\n",
    "Then called x_prt.send(toby) which sent the pointer to Toby. This did not move the data, it moved the pointer to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see above, Bob still has the actual data (data is always stored in a LocalTensor type). \n",
    "jake._objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16200693430: (Wrapper)>[PointerTensor | toby:16200693430 -> jake:74887559502]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toby, on the other hand, has x_ptr!! (notice how it points at bob)\n",
    "toby._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:16200693430 -> jake:74887559502]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we can use .get() to get x_ptr back from Toby\n",
    "\n",
    "x_ptr = pointer_to_x_ptr.get()\n",
    "x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #and then we can use x_ptr to get x back from Jake!\n",
    "\n",
    "x = x_ptr.get()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like normal pointers - can perform arbitrary PyTorch operations across Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jake._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p2x = torch.tensor([1,2,3,4,5]).send(jake).send(toby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = p2p2x + p2p2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3886126330: tensor([1, 2, 3, 4, 5]),\n",
       " 62481850534: tensor([ 2,  4,  6,  8, 10])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jake._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11194324781: (Wrapper)>[PointerTensor | toby:11194324781 -> jake:3886126330],\n",
       " 14342832401: (Wrapper)>[PointerTensor | toby:14342832401 -> jake:62481850534]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  4,  6,  8, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.get().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3886126330: tensor([1, 2, 3, 4, 5])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jake._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11194324781: (Wrapper)>[PointerTensor | toby:11194324781 -> jake:3886126330]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2p2x.get().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jake._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toby._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pointer Chain Operations**\n",
    "Whenever we called a .send() or a .get() operation, it called that operation directly on the tensor on our local machine. However, it we have a chain of pointers, sometimes want to call operations like .get() or .send() on the last pointer in the chain (such as sending data directly from one worker to another). To accomplish this, use functions designed for this privacy preserving operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is now a pointer to the data which lives on jake's machine\n",
    "x = torch.tensor([1,2,3,4,5]).send(jake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  jake: {20104235647: tensor([1, 2, 3, 4, 5])}\n",
      "toby: {}\n"
     ]
    }
   ],
   "source": [
    "print('  jake:', jake._objects)\n",
    "print('toby:',toby._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.move(toby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jake: {}\n",
      "toby: {20104235647: tensor([1, 2, 3, 4, 5])}\n"
     ]
    }
   ],
   "source": [
    "print('jake:', jake._objects)\n",
    "print('toby:',toby._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:61497175931 -> toby:20104235647]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning with Model Averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous part, trained model with simplified federated learning, where we had to trust the mode owner to be able to see worker's gradients.\n",
    "\n",
    "In this tutorial, use advanced aggregation tools to allow the weights to be aggregated by a trusted \"secure worker\" before the final resulting model is sent back to the model owner (us)\n",
    "\n",
    "only secure worker can see whose weights came from whom. May be able to tell which parts of model changed, but don't know which worker caused change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "\n",
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "bobs_data = data[0:2].send(bob)\n",
    "bobs_target = target[0:2].send(bob)\n",
    "\n",
    "alices_data = data[2:].send(alice)\n",
    "alices_target = target[2:].send(alice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send a copy of current model to Alice & Bob so that they can perform steps of learning on their own dataset\n",
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(1.4295) Alice:tensor(11.6062)\n",
      "Bob:tensor(0.3257) Alice:tensor(0.1180)\n",
      "Bob:tensor(0.0750) Alice:tensor(0.0248)\n",
      "Bob:tensor(0.0180) Alice:tensor(0.0201)\n",
      "Bob:tensor(0.0049) Alice:tensor(0.0167)\n",
      "Bob:tensor(0.0018) Alice:tensor(0.0139)\n",
      "Bob:tensor(0.0010) Alice:tensor(0.0116)\n",
      "Bob:tensor(0.0007) Alice:tensor(0.0096)\n",
      "Bob:tensor(0.0006) Alice:tensor(0.0080)\n",
      "Bob:tensor(0.0005) Alice:tensor(0.0067)\n"
     ]
    }
   ],
   "source": [
    "#Federated Learning via Secure Averaging - each data owner first trains their model for\n",
    "#several iterations locally before the models are average together\n",
    "for i in range(10):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(bobs_data)\n",
    "    bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(alices_data)\n",
    "    alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that each data owner has partially trained model, time to average them together in a secure way. Must instruct Alice & Bob to send their model to the secure server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alices_model.move(secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model.move(secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last step is to average Bob and Alice's trained models together\n",
    "# and use this to set the values for our global \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "    model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate this multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.0008) Alice:tensor(0.0161)\n",
      "Bob:tensor(0.0025) Alice:tensor(0.0090)\n",
      "Bob:tensor(0.0035) Alice:tensor(0.0045)\n",
      "Bob:tensor(0.0039) Alice:tensor(0.0023)\n",
      "Bob:tensor(0.0038) Alice:tensor(0.0012)\n",
      "Bob:tensor(0.0034) Alice:tensor(0.0006)\n",
      "Bob:tensor(0.0029) Alice:tensor(0.0003)\n",
      "Bob:tensor(0.0025) Alice:tensor(0.0002)\n",
      "Bob:tensor(0.0020) Alice:tensor(0.0001)\n",
      "Bob:tensor(0.0016) Alice:tensor(7.7089e-05)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "worker_iters = 5\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "    \n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "    alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "        bobs_pred = bobs_model(bobs_data)\n",
    "        bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "        bobs_loss.backward()\n",
    "\n",
    "        bobs_opt.step()\n",
    "        bobs_loss = bobs_loss.get().data\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "        alices_pred = alices_model(alices_data)\n",
    "        alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "        alices_loss.backward()\n",
    "\n",
    "        alices_opt.step()\n",
    "        alices_loss = alices_loss.get().data\n",
    "    \n",
    "    alices_model.move(secure_worker)\n",
    "    bobs_model.move(secure_worker)\n",
    "    with torch.no_grad():\n",
    "        model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "        model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data)\n",
    "loss = ((preds - target) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1177],\n",
      "        [0.0991],\n",
      "        [0.8744],\n",
      "        [0.8558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "tensor(0.0602)\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(target)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pysyft Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "\t- Hooking PyTorch\n",
      "\t- Creating Virtual Workers:\n",
      "\t\t- bob\n",
      "\t\t- theo\n",
      "\t\t- jason\n",
      "\t\t- alice\n",
      "\t\t- andy\n",
      "\t\t- jon\n",
      "\tStoring hook and workers as global variables...\n",
      "\tLoading datasets from SciKit Learn...\n",
      "\t\t- Boston Housing Dataset\n",
      "\t\t- Diabetes Dataset\n",
      "\t\t- Breast Cancer Dataset\n",
      "\t- Digits Dataset\n",
      "\t\t- Iris Dataset\n",
      "\t\t- Wine Dataset\n",
      "\t\t- Linnerud Dataset\n",
      "\tDistributing Datasets Amongst Workers...\n",
      "\tCollecting workers into a VirtualGrid...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sy.create_sandbox(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<VirtualWorker id:bob #objects:17>,\n",
       " <VirtualWorker id:theo #objects:14>,\n",
       " <VirtualWorker id:jason #objects:14>,\n",
       " <VirtualWorker id:alice #objects:17>,\n",
       " <VirtualWorker id:andy #objects:14>,\n",
       " <VirtualWorker id:jon #objects:14>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<syft.frameworks.torch.hook.hook.TorchHook at 0x7f7a2635f520>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:bob #objects:17>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to search for datasets on a remote machine. In this example, a research lab wants to query hospitals for a \"radio\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4,5]).tag(\"#radio\", \"#hospital1\").describe(\"The input datapoints to the hospital1 dataset.\")\n",
    "y = torch.tensor([5,4,3,2,1]).tag(\"#radio\", \"#hospital2\").describe(\"The input datapoints to the hospital2 dataset.\")\n",
    "z = torch.tensor([1,2,3,4,5]).tag(\"#fun\", \"#mnist\",).describe(\"The images in the MNIST training dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])\n",
       "\tTags: #hospital1 #radio \n",
       "\tDescription: The input datapoints to the hospital1 dataset....\n",
       "\tShape: torch.Size([5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.send(bob)\n",
    "y = y.send(bob)\n",
    "z = z.send(bob)\n",
    "\n",
    "# this searches for exact match within a tag or within the description\n",
    "results = bob.search([\"#radio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 3, 4, 5])\n",
       " \tTags: #hospital1 #radio \n",
       " \tDescription: The input datapoints to the hospital1 dataset....\n",
       " \tShape: torch.Size([5]),\n",
       " tensor([5, 4, 3, 2, 1])\n",
       " \tTags: #radio #hospital2 \n",
       " \tDescription: The input datapoints to the hospital2 dataset....\n",
       " \tShape: torch.Size([5])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input datapoints to the hospital1 dataset.\n"
     ]
    }
   ],
   "source": [
    "print(results[0].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for datasets that are pre-populated on the sandbox workers\n",
    "boston_housing_results = bob.search([\"#boston\", \"#housing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Grid is a collection of workers that gives some convenienve functions for when you want to put together a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sy.PrivateGridNetwork(*workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid.search(\"#boston\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = grid.search(\"#boston\",\"#data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_target = grid.search(\"#boston\",\"#target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning on MNIST using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Classification Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Short Name</th>\n",
       "      <th>EBITDA to Net Sales:Q</th>\n",
       "      <th>GM:Q</th>\n",
       "      <th>Net D/E LF</th>\n",
       "      <th>Total Market Value LF</th>\n",
       "      <th>ROE LF</th>\n",
       "      <th>ROA LF</th>\n",
       "      <th>Curr Liab LF</th>\n",
       "      <th>Net Int Cov</th>\n",
       "      <th>...</th>\n",
       "      <th>CFO T12M</th>\n",
       "      <th>Net Debt to EBITDA LF</th>\n",
       "      <th>Debt/EBITDA LF</th>\n",
       "      <th>ST Brrwng LF</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>LT Brrwng LF</th>\n",
       "      <th>Net Debt LF</th>\n",
       "      <th>Moody's Issuer Rtg</th>\n",
       "      <th>Fitch Issr ST Rtg</th>\n",
       "      <th>S&amp;P LT LC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXMC US Equity</td>\n",
       "      <td>TIREX CORP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45801300.00%</td>\n",
       "      <td>4.98M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-192.63k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>675.75k</td>\n",
       "      <td>670.05k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUBG US Equity</td>\n",
       "      <td>ENTREPRENEUR UNI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1847.86%</td>\n",
       "      <td>182.03k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.02k</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>176.88k</td>\n",
       "      <td>170.98k</td>\n",
       "      <td>0</td>\n",
       "      <td>176.41k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPQS US Equity</td>\n",
       "      <td>SPORTSQUEST INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.16M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.34%</td>\n",
       "      <td>340.00k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.38k</td>\n",
       "      <td>0</td>\n",
       "      <td>-96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRH US Equity</td>\n",
       "      <td>SCORES HOLDING C</td>\n",
       "      <td>-120.82%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882.56k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>591.33%</td>\n",
       "      <td>325.16k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-449.80k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.08k</td>\n",
       "      <td>330.37k</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.38k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBR US Equity</td>\n",
       "      <td>SABINE ROYALTY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-167.83</td>\n",
       "      <td>394.61M</td>\n",
       "      <td>732.52%</td>\n",
       "      <td>488.27%</td>\n",
       "      <td>3.56M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>41.57M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>401.66M</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.36M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>MDKM US Equity</td>\n",
       "      <td>MDECHEM INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.11k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IHGP US Equity</td>\n",
       "      <td>INTERACT HOLDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>AVOT US Equity</td>\n",
       "      <td>AMER VIDEO TELEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>MMTS US Equity</td>\n",
       "      <td>MULTI-MEDIA TUTL</td>\n",
       "      <td>-59.34%</td>\n",
       "      <td>86.25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.89M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.97M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.24M</td>\n",
       "      <td>32.53k</td>\n",
       "      <td>538.02k</td>\n",
       "      <td>2.78M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>FBVI US Equity</td>\n",
       "      <td>FNC BANC CORP/IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ticker        Short Name EBITDA to Net Sales:Q    GM:Q  \\\n",
       "0     TXMC US Equity        TIREX CORP                   NaN     NaN   \n",
       "1     EUBG US Equity  ENTREPRENEUR UNI                   NaN     NaN   \n",
       "2     SPQS US Equity   SPORTSQUEST INC                   NaN     NaN   \n",
       "3     SCRH US Equity  SCORES HOLDING C              -120.82%     NaN   \n",
       "4      SBR US Equity    SABINE ROYALTY                   NaN     NaN   \n",
       "...              ...               ...                   ...     ...   \n",
       "2995  MDKM US Equity       MDECHEM INC                   NaN     NaN   \n",
       "2996  IHGP US Equity  INTERACT HOLDING                   NaN     NaN   \n",
       "2997  AVOT US Equity  AMER VIDEO TELEC                   NaN     NaN   \n",
       "2998  MMTS US Equity  MULTI-MEDIA TUTL               -59.34%  86.25%   \n",
       "2999  FBVI US Equity  FNC BANC CORP/IN                   NaN     NaN   \n",
       "\n",
       "      Net D/E LF Total Market Value LF   ROE LF        ROA LF Curr Liab LF  \\\n",
       "0            NaN                   NaN      NaN  45801300.00%        4.98M   \n",
       "1            NaN                 1.10M      NaN      1847.86%      182.03k   \n",
       "2            NaN                 1.16M      NaN       800.34%      340.00k   \n",
       "3            NaN               882.56k      NaN       591.33%      325.16k   \n",
       "4        -167.83               394.61M  732.52%       488.27%        3.56M   \n",
       "...          ...                   ...      ...           ...          ...   \n",
       "2995         NaN                   NaN      NaN           NaN          NaN   \n",
       "2996         NaN                   NaN      NaN           NaN          NaN   \n",
       "2997         NaN                   NaN      NaN           NaN          NaN   \n",
       "2998         NaN                 2.89M      NaN           NaN        6.97M   \n",
       "2999         NaN                   NaN      NaN           NaN          NaN   \n",
       "\n",
       "      Net Int Cov  ...  CFO T12M Net Debt to EBITDA LF Debt/EBITDA LF  \\\n",
       "0             NaN  ...  -192.63k                   NaN            NaN   \n",
       "1             NaN  ...   -45.02k                  0.39           0.39   \n",
       "2             NaN  ...      -165                     0              0   \n",
       "3             NaN  ...  -449.80k                   NaN            NaN   \n",
       "4             NaN  ...    41.57M                   NaN            NaN   \n",
       "...           ...  ...       ...                   ...            ...   \n",
       "2995          NaN  ...       NaN                   NaN            NaN   \n",
       "2996          NaN  ...       NaN                   NaN            NaN   \n",
       "2997          NaN  ...       NaN                   NaN            NaN   \n",
       "2998          NaN  ...       NaN                   NaN            NaN   \n",
       "2999          NaN  ...       NaN                   NaN            NaN   \n",
       "\n",
       "     ST Brrwng LF Market Cap LT Brrwng LF Net Debt LF Moody's Issuer Rtg  \\\n",
       "0         675.75k    670.05k          NaN         NaN                NaN   \n",
       "1         176.88k    170.98k            0     176.41k                NaN   \n",
       "2               0      1.38k            0         -96                NaN   \n",
       "3          22.08k    330.37k            0      -3.38k                NaN   \n",
       "4               0    401.66M            0      -8.36M                NaN   \n",
       "...           ...        ...          ...         ...                ...   \n",
       "2995          NaN     32.11k          NaN         NaN                NaN   \n",
       "2996          NaN      40.67          NaN         NaN                NaN   \n",
       "2997          NaN        NaN          NaN         NaN                NaN   \n",
       "2998        2.24M     32.53k      538.02k       2.78M                NaN   \n",
       "2999          NaN        NaN          NaN         NaN                NaN   \n",
       "\n",
       "     Fitch Issr ST Rtg S&P LT LC  \n",
       "0                  NaN       NaN  \n",
       "1                  NaN       NaN  \n",
       "2                  NaN       NaN  \n",
       "3                  NaN       NaN  \n",
       "4                  NaN       NaN  \n",
       "...                ...       ...  \n",
       "2995               NaN       NaN  \n",
       "2996               NaN       NaN  \n",
       "2997               NaN       NaN  \n",
       "2998               NaN       NaN  \n",
       "2999               NaN       NaN  \n",
       "\n",
       "[3000 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data = pd.read_csv('../pytorch/grid1.csv')\n",
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "stock_data = stock_data.rename(columns={\"Ticker\": \"ticker\", \"Short Name\": \"full_name\", \"EBITDA to Net Sales:Q\":\"ebitda/net_sales\", \"GM:Q\":\"gm\", \"Net D/E LF\":\"net_debt/e\", \"Total Market Value LF\": \"mv\", \"ROE LF\": \"roe\", \"ROA LF\": \"roa\", \"Curr Liab LF\":\"liabilities\", \"Net Int Cov\":\"net_interest_coverage\", \"CFO T12M\": \"cfo\", \"Net Debt to EBITDA LF\":\"net_debt/ebitda\", \"Debt/EBITDA LF\":\"debt/ebitda\", \"ST Brrwng LF\":\"st_borrowing\", \"LT Brrwng LF\":\"lt_borrowing\", \"Net Debt LF\":\"net_debt\",\"Moody's Issuer Rtg\":\"m_rtg\", \"Fitch Issr ST Rtg\":\"f_rtg\", \"S&P LT LC\":\"sp_rtg\", \"Market Cap\":\"mc\", \"CFO/Debt LF\":\"cfo/debt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = stock_data.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert T to trillions, B to billions, M to millions, K to thousands. Thanks for truncating Bloomberg! We're using regex expressions here\n",
    "stock_data['mv'] = stock_data['mv'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['liabilities'] = stock_data['liabilities'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['cfo'] = stock_data['cfo'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['st_borrowing'] = stock_data['st_borrowing'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['lt_borrowing'] = stock_data['lt_borrowing'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['net_debt'] = stock_data['net_debt'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['mc'] = stock_data['mc'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['net_debt/ebitda'] = stock_data['net_debt/ebitda'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['debt/ebitda'] = stock_data['debt/ebitda'].replace({'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', '[tT]': '*1e12'}, regex=True).map(pd.eval).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>full_name</th>\n",
       "      <th>ebitda/net_sales</th>\n",
       "      <th>gm</th>\n",
       "      <th>net_debt/e</th>\n",
       "      <th>mv</th>\n",
       "      <th>roe</th>\n",
       "      <th>roa</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>net_interest_coverage</th>\n",
       "      <th>...</th>\n",
       "      <th>cfo</th>\n",
       "      <th>net_debt/ebitda</th>\n",
       "      <th>debt/ebitda</th>\n",
       "      <th>st_borrowing</th>\n",
       "      <th>mc</th>\n",
       "      <th>lt_borrowing</th>\n",
       "      <th>net_debt</th>\n",
       "      <th>m_rtg</th>\n",
       "      <th>f_rtg</th>\n",
       "      <th>sp_rtg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXMC US Equity</td>\n",
       "      <td>TIREX CORP</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45801300.00%</td>\n",
       "      <td>4980000</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-192630</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>675750</td>\n",
       "      <td>670050</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUBG US Equity</td>\n",
       "      <td>ENTREPRENEUR UNI</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1100000</td>\n",
       "      <td>-1</td>\n",
       "      <td>1847.86%</td>\n",
       "      <td>182030</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-45020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>176880</td>\n",
       "      <td>170980</td>\n",
       "      <td>0</td>\n",
       "      <td>176410</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPQS US Equity</td>\n",
       "      <td>SPORTSQUEST INC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1160000</td>\n",
       "      <td>-1</td>\n",
       "      <td>800.34%</td>\n",
       "      <td>340000</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1380</td>\n",
       "      <td>0</td>\n",
       "      <td>-96</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCRH US Equity</td>\n",
       "      <td>SCORES HOLDING C</td>\n",
       "      <td>-120.82%</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>882560</td>\n",
       "      <td>-1</td>\n",
       "      <td>591.33%</td>\n",
       "      <td>325160</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-449800</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>22080</td>\n",
       "      <td>330370</td>\n",
       "      <td>0</td>\n",
       "      <td>-3380</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBR US Equity</td>\n",
       "      <td>SABINE ROYALTY</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-167.83</td>\n",
       "      <td>394610000</td>\n",
       "      <td>732.52%</td>\n",
       "      <td>488.27%</td>\n",
       "      <td>3560000</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>41570000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>401660000</td>\n",
       "      <td>0</td>\n",
       "      <td>-8359999</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>MDKM US Equity</td>\n",
       "      <td>MDECHEM INC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>32110</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IHGP US Equity</td>\n",
       "      <td>INTERACT HOLDING</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>AVOT US Equity</td>\n",
       "      <td>AMER VIDEO TELEC</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>MMTS US Equity</td>\n",
       "      <td>MULTI-MEDIA TUTL</td>\n",
       "      <td>-59.34%</td>\n",
       "      <td>86.25%</td>\n",
       "      <td>-1</td>\n",
       "      <td>2890000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6970000</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2240000</td>\n",
       "      <td>32530</td>\n",
       "      <td>538020</td>\n",
       "      <td>2780000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>FBVI US Equity</td>\n",
       "      <td>FNC BANC CORP/IN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ticker         full_name ebitda/net_sales      gm net_debt/e  \\\n",
       "0     TXMC US Equity        TIREX CORP               -1      -1         -1   \n",
       "1     EUBG US Equity  ENTREPRENEUR UNI               -1      -1         -1   \n",
       "2     SPQS US Equity   SPORTSQUEST INC               -1      -1         -1   \n",
       "3     SCRH US Equity  SCORES HOLDING C         -120.82%      -1         -1   \n",
       "4      SBR US Equity    SABINE ROYALTY               -1      -1    -167.83   \n",
       "...              ...               ...              ...     ...        ...   \n",
       "2995  MDKM US Equity       MDECHEM INC               -1      -1         -1   \n",
       "2996  IHGP US Equity  INTERACT HOLDING               -1      -1         -1   \n",
       "2997  AVOT US Equity  AMER VIDEO TELEC               -1      -1         -1   \n",
       "2998  MMTS US Equity  MULTI-MEDIA TUTL          -59.34%  86.25%         -1   \n",
       "2999  FBVI US Equity  FNC BANC CORP/IN               -1      -1         -1   \n",
       "\n",
       "             mv      roe           roa  liabilities net_interest_coverage  \\\n",
       "0            -1       -1  45801300.00%      4980000                    -1   \n",
       "1       1100000       -1      1847.86%       182030                    -1   \n",
       "2       1160000       -1       800.34%       340000                    -1   \n",
       "3        882560       -1       591.33%       325160                    -1   \n",
       "4     394610000  732.52%       488.27%      3560000                    -1   \n",
       "...         ...      ...           ...          ...                   ...   \n",
       "2995         -1       -1            -1           -1                    -1   \n",
       "2996         -1       -1            -1           -1                    -1   \n",
       "2997         -1       -1            -1           -1                    -1   \n",
       "2998    2890000       -1            -1      6970000                    -1   \n",
       "2999         -1       -1            -1           -1                    -1   \n",
       "\n",
       "      ...       cfo  net_debt/ebitda  debt/ebitda  st_borrowing         mc  \\\n",
       "0     ...   -192630               -1           -1        675750     670050   \n",
       "1     ...    -45020                0            0        176880     170980   \n",
       "2     ...      -165                0            0             0       1380   \n",
       "3     ...   -449800               -1           -1         22080     330370   \n",
       "4     ...  41570000               -1           -1             0  401660000   \n",
       "...   ...       ...              ...          ...           ...        ...   \n",
       "2995  ...        -1               -1           -1            -1      32110   \n",
       "2996  ...        -1               -1           -1            -1         40   \n",
       "2997  ...        -1               -1           -1            -1         -1   \n",
       "2998  ...        -1               -1           -1       2240000      32530   \n",
       "2999  ...        -1               -1           -1            -1         -1   \n",
       "\n",
       "      lt_borrowing  net_debt  m_rtg f_rtg sp_rtg  \n",
       "0               -1        -1     -1    -1     -1  \n",
       "1                0    176410     -1    -1     -1  \n",
       "2                0       -96     -1    -1     -1  \n",
       "3                0     -3380     -1    -1     -1  \n",
       "4                0  -8359999     -1    -1     -1  \n",
       "...            ...       ...    ...   ...    ...  \n",
       "2995            -1        -1     -1    -1     -1  \n",
       "2996            -1        -1     -1    -1     -1  \n",
       "2997            -1        -1     -1    -1     -1  \n",
       "2998        538020   2780000     -1    -1     -1  \n",
       "2999            -1        -1     -1    -1     -1  \n",
       "\n",
       "[3000 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert % to decimal\n",
    "#first, we use regex to replace '-' with -1* and to remove the % sign\n",
    "stock_data['ebitda/net_sales'] = stock_data['ebitda/net_sales'].replace({'-':'-1*', '%':''}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['roe'] = stock_data['roe'].replace({'-':'-1*', '%':''}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['roa'] = stock_data['roa'].replace({'-':'-1*', '%':''}, regex=True).map(pd.eval).astype(int)\n",
    "stock_data['gm'] = stock_data['gm'].replace({'-':'-1*', '%':''}, regex=True).map(pd.eval).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we must divide by 100 to convert the percents to decimal\n",
    "stock_data['ebitda/net_sales'] = stock_data[stock_data['ebitda/net_sales'] != -1]['ebitda/net_sales'].div(100)\n",
    "stock_data['roe'] = stock_data[stock_data['roe'] != -1]['roe'].div(100)\n",
    "stock_data['roa'] = stock_data[stock_data['roa'] != -1]['roa'].div(100)\n",
    "stock_data['gm'] = stock_data[stock_data['gm'] != -1]['gm'].div(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refill all NaN values with our placeholder, -1\n",
    "stock_data = stock_data.fillna('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate any rows that don't have ratings from any agencies (moody's, fitch, nor s&p)\n",
    "#this is a pretty cheeky way to accomplish this problem using one line - check if all the data isn't the same (the min and the max are not =). If min(x) and max(x) are\n",
    "#the same, x must be -1\n",
    "#this works in this case because the ratings system for each agency is different\n",
    "stock_data = stock_data[stock_data.iloc[:,18:22].apply(lambda x: min(x) != max(x), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global temp\n",
    "temp = stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dict of how we'll interpret ratings. For entries\n",
    "#with multiple entries, we'll take the average\n",
    "ratings_dict = {'AAA':1, 'AA+':2, 'AA':3, 'AA-':4, 'A+':5, 'A':6, 'A-':7, 'BBB+':8, 'BBB':9, 'BBB-':10, 'BB+':11, 'BB':12, 'BB-':13, 'B+':14, 'B':15, 'B-':16, 'CCC+':17, 'CCC':18, 'CCC-':19, 'CC':20, 'C':21, 'SD':22, 'D':23, 'Aaa':1, 'Aa1':2, 'Aa2':3, 'Aa3':3, 'A1':4, 'A2':5, 'A3':6, 'Baa1':7, 'Baa2':8, 'Baa3':9, 'Ba1':10, 'Ba2':11, 'Ba3':12, 'F1+':3, 'F1':6, 'F2':8, 'F3':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this data is sparse - we need to fill in the empty unknown features. Some typical approaches are regression of the column\n",
    "#the mean of the column, or stochastic regression of the column. We will try the column mean for all others\n",
    "#with the same rating for now. We also have to remember to ignore WRs (withdrawn ratings)\n",
    "\n",
    "#find the average value to replace missing data given a rating and column\n",
    "def find_class_mean(data):\n",
    "    col = len(data)\n",
    "    col_names = list(temp.columns)\n",
    "    rating = []\n",
    "    count = 0\n",
    "    data = np.array(data)\n",
    "    for i in range(col-3, col):\n",
    "        if data[i] != '-1' and data[i] != 'WR':\n",
    "            rating.append(data[i])\n",
    "            \n",
    "            if count == 0:\n",
    "                to_avg_df = temp[temp[col_names[i]] == data[i]] \n",
    "                new_rating = ratings_dict[data[i]]\n",
    "            else:\n",
    "                to_avg_df.append(temp[temp[col_names[i]] == data[i]])\n",
    "                new_rating = new_rating + ratings_dict[data[i]]\n",
    "            \n",
    "            count = count + 1\n",
    "    new_rating = new_rating/count\n",
    "    for i in range(2, col-3):\n",
    "        if data[i] == '-1' or data[i] == -1:\n",
    "            calc = to_avg_df[col_names[i]]\n",
    "            calc = pd.to_numeric(calc)\n",
    "            men = calc.mean()\n",
    "            data[i] = men\n",
    "    \n",
    "    data = np.append(data, new_rating)\n",
    "    \n",
    "    if (new_rating <= 10):\n",
    "        data = np.append(data, 1)\n",
    "    else:\n",
    "        data = np.append(data, 0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply our empty data averager to the entire dataframe\n",
    "col_names = list(stock_data.columns)\n",
    "new_data = stock_data.apply(find_class_mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the returned data into a numpy matrix\n",
    "new_data = np.vstack(new_data)\n",
    "col_names = np.append(col_names, 'label')\n",
    "col_names = np.append(col_names, 'i/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruct the dataframe\n",
    "data = pd.DataFrame(new_data, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>full_name</th>\n",
       "      <th>ebitda/net_sales</th>\n",
       "      <th>gm</th>\n",
       "      <th>net_debt/e</th>\n",
       "      <th>mv</th>\n",
       "      <th>roe</th>\n",
       "      <th>roa</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>net_interest_coverage</th>\n",
       "      <th>...</th>\n",
       "      <th>debt/ebitda</th>\n",
       "      <th>st_borrowing</th>\n",
       "      <th>mc</th>\n",
       "      <th>lt_borrowing</th>\n",
       "      <th>net_debt</th>\n",
       "      <th>m_rtg</th>\n",
       "      <th>f_rtg</th>\n",
       "      <th>sp_rtg</th>\n",
       "      <th>label</th>\n",
       "      <th>i/g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASCS US Equity</td>\n",
       "      <td>AMERICAN CR-PREF</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>59.14</td>\n",
       "      <td>8.45358e+10</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.85</td>\n",
       "      <td>351400000</td>\n",
       "      <td>50.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>118800000</td>\n",
       "      <td>2.60923e+10</td>\n",
       "      <td>128060000</td>\n",
       "      <td>246730000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>BBB+</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHRT US Equity</td>\n",
       "      <td>IHEARTMEDIA-CL A</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>0.61</td>\n",
       "      <td>490.1</td>\n",
       "      <td>7370000000</td>\n",
       "      <td>-0.316889</td>\n",
       "      <td>0.82</td>\n",
       "      <td>645840000</td>\n",
       "      <td>43.69</td>\n",
       "      <td>...</td>\n",
       "      <td>19.4333</td>\n",
       "      <td>112590000</td>\n",
       "      <td>1040000000</td>\n",
       "      <td>6710000000</td>\n",
       "      <td>6170000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WFTLF US Equity</td>\n",
       "      <td>WEATHERFORD INTE</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.24</td>\n",
       "      <td>98.93</td>\n",
       "      <td>2560000000</td>\n",
       "      <td>-0.670909</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1640000000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.27273</td>\n",
       "      <td>116000000</td>\n",
       "      <td>140030000</td>\n",
       "      <td>2400000000</td>\n",
       "      <td>1840000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CCC</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBL US Equity</td>\n",
       "      <td>GAMCO INVESTO-A</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.177857</td>\n",
       "      <td>-82.08</td>\n",
       "      <td>328670000</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.62101e+09</td>\n",
       "      <td>3.73664</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347510000</td>\n",
       "      <td>24200000</td>\n",
       "      <td>-53640000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EAF US Equity</td>\n",
       "      <td>GRAFTECH INTERNA</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>213.171</td>\n",
       "      <td>4010000000</td>\n",
       "      <td>-0.0308772</td>\n",
       "      <td>0.43</td>\n",
       "      <td>222540000</td>\n",
       "      <td>7.87</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>138000</td>\n",
       "      <td>1720000000</td>\n",
       "      <td>1810000000</td>\n",
       "      <td>1660000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>BB-</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>NNHE US Equity</td>\n",
       "      <td>NEENAH ENTERPRIS</td>\n",
       "      <td>-0.769211</td>\n",
       "      <td>0.138158</td>\n",
       "      <td>624.248</td>\n",
       "      <td>2.31264e+09</td>\n",
       "      <td>-0.708421</td>\n",
       "      <td>-0.171579</td>\n",
       "      <td>4.32593e+08</td>\n",
       "      <td>-0.300263</td>\n",
       "      <td>...</td>\n",
       "      <td>9.63158</td>\n",
       "      <td>1.4386e+08</td>\n",
       "      <td>6.05584e+08</td>\n",
       "      <td>1.57946e+09</td>\n",
       "      <td>1.62882e+09</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CCC+</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>AMK US Equity</td>\n",
       "      <td>ASSETMARK FINANC</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0904808</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1800000000</td>\n",
       "      <td>0.0194231</td>\n",
       "      <td>-0.0101923</td>\n",
       "      <td>3.70428e+09</td>\n",
       "      <td>3.55029</td>\n",
       "      <td>...</td>\n",
       "      <td>3.67308</td>\n",
       "      <td>2910000</td>\n",
       "      <td>1930000000</td>\n",
       "      <td>158380000</td>\n",
       "      <td>81120000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>BB+</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>OCESO US Equity</td>\n",
       "      <td>OCEAN SPRAY CRAN</td>\n",
       "      <td>-0.0928571</td>\n",
       "      <td>-0.177857</td>\n",
       "      <td>99.9571</td>\n",
       "      <td>2.14083e+10</td>\n",
       "      <td>0.0287143</td>\n",
       "      <td>-0.0105714</td>\n",
       "      <td>2.62101e+09</td>\n",
       "      <td>3.73664</td>\n",
       "      <td>...</td>\n",
       "      <td>4.22857</td>\n",
       "      <td>1.09516e+09</td>\n",
       "      <td>1.08925e+10</td>\n",
       "      <td>5.24545e+09</td>\n",
       "      <td>5.04906e+09</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>VKSC US Equity</td>\n",
       "      <td>VISKASE COS I</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>723.67</td>\n",
       "      <td>453970000</td>\n",
       "      <td>-0.670909</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>351670000</td>\n",
       "      <td>0.520909</td>\n",
       "      <td>...</td>\n",
       "      <td>4.27273</td>\n",
       "      <td>269150000</td>\n",
       "      <td>54140000</td>\n",
       "      <td>31950000</td>\n",
       "      <td>288240000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>CCC</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>ENGH US Equity</td>\n",
       "      <td>ENERGY HARBOR CO</td>\n",
       "      <td>-0.447647</td>\n",
       "      <td>-0.417941</td>\n",
       "      <td>97.3282</td>\n",
       "      <td>2.15519e+10</td>\n",
       "      <td>-0.00794118</td>\n",
       "      <td>-0.0205882</td>\n",
       "      <td>1.32312e+09</td>\n",
       "      <td>1.40912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.70588</td>\n",
       "      <td>1.24131e+09</td>\n",
       "      <td>5.35642e+09</td>\n",
       "      <td>4.57904e+09</td>\n",
       "      <td>4.68208e+09</td>\n",
       "      <td>Baa3</td>\n",
       "      <td>-1</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1294 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ticker         full_name ebitda/net_sales         gm  \\\n",
       "0      ASCS US Equity  AMERICAN CR-PREF             0.08      -0.04   \n",
       "1      IHRT US Equity  IHEARTMEDIA-CL A            -2.09       0.61   \n",
       "2     WFTLF US Equity  WEATHERFORD INTE            -0.52       0.24   \n",
       "3       GBL US Equity   GAMCO INVESTO-A             0.37  -0.177857   \n",
       "4       EAF US Equity  GRAFTECH INTERNA             0.55       0.56   \n",
       "...               ...               ...              ...        ...   \n",
       "1289   NNHE US Equity  NEENAH ENTERPRIS        -0.769211   0.138158   \n",
       "1290    AMK US Equity  ASSETMARK FINANC              0.1  0.0904808   \n",
       "1291  OCESO US Equity  OCEAN SPRAY CRAN       -0.0928571  -0.177857   \n",
       "1292   VKSC US Equity     VISKASE COS I             0.15        0.2   \n",
       "1293   ENGH US Equity  ENERGY HARBOR CO        -0.447647  -0.417941   \n",
       "\n",
       "     net_debt/e           mv         roe        roa  liabilities  \\\n",
       "0         59.14  8.45358e+10        2.47       0.85    351400000   \n",
       "1         490.1   7370000000   -0.316889       0.82    645840000   \n",
       "2         98.93   2560000000   -0.670909       0.49   1640000000   \n",
       "3        -82.08    328670000        1.58       0.48  2.62101e+09   \n",
       "4       213.171   4010000000  -0.0308772       0.43    222540000   \n",
       "...         ...          ...         ...        ...          ...   \n",
       "1289    624.248  2.31264e+09   -0.708421  -0.171579  4.32593e+08   \n",
       "1290       9.27   1800000000   0.0194231 -0.0101923  3.70428e+09   \n",
       "1291    99.9571  2.14083e+10   0.0287143 -0.0105714  2.62101e+09   \n",
       "1292     723.67    453970000   -0.670909      -0.18    351670000   \n",
       "1293    97.3282  2.15519e+10 -0.00794118 -0.0205882  1.32312e+09   \n",
       "\n",
       "     net_interest_coverage  ... debt/ebitda st_borrowing           mc  \\\n",
       "0                     50.4  ...           0    118800000  2.60923e+10   \n",
       "1                    43.69  ...     19.4333    112590000   1040000000   \n",
       "2                     11.1  ...     4.27273    116000000    140030000   \n",
       "3                  3.73664  ...           0            0    347510000   \n",
       "4                     7.87  ...           1       138000   1720000000   \n",
       "...                    ...  ...         ...          ...          ...   \n",
       "1289             -0.300263  ...     9.63158   1.4386e+08  6.05584e+08   \n",
       "1290               3.55029  ...     3.67308      2910000   1930000000   \n",
       "1291               3.73664  ...     4.22857  1.09516e+09  1.08925e+10   \n",
       "1292              0.520909  ...     4.27273    269150000     54140000   \n",
       "1293               1.40912  ...     3.70588  1.24131e+09  5.35642e+09   \n",
       "\n",
       "     lt_borrowing     net_debt m_rtg f_rtg sp_rtg label i/g  \n",
       "0       128060000    246730000    -1    -1   BBB+     8   1  \n",
       "1      6710000000   6170000000    -1    -1      B    15   0  \n",
       "2      2400000000   1840000000    -1    -1    CCC    18   0  \n",
       "3        24200000    -53640000    -1    -1   BBB-    10   1  \n",
       "4      1810000000   1660000000    -1    -1    BB-    13   0  \n",
       "...           ...          ...   ...   ...    ...   ...  ..  \n",
       "1289  1.57946e+09  1.62882e+09    -1    -1   CCC+    17   0  \n",
       "1290    158380000     81120000    -1    -1    BB+    11   0  \n",
       "1291  5.24545e+09  5.04906e+09    -1    -1   BBB-    10   1  \n",
       "1292     31950000    288240000    -1    -1    CCC    18   0  \n",
       "1293  4.57904e+09  4.68208e+09  Baa3    -1   BBB-   9.5   1  \n",
       "\n",
       "[1294 rows x 23 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a dictionary of all of the credit tranches so we can give our companies a single label\n",
    "#right now, there are 3, moody's, fitch, and S&P\n",
    "m_rtg = np.unique(data['m_rtg'])\n",
    "f_rtg = np.unique(data['f_rtg'])\n",
    "sp_rtg = np.unique(data['sp_rtg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-1', 'B', 'F1', 'F1+', 'F2', 'F3'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rtg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a multiclass classifier.\n",
    "#Given credit quality feature it will predict which tranche the bond belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as alot of our features are likely co-linear (only differ by a consant, it is prudent\n",
    "#to try to figure out which are most valuable using a feature selection technique.\n",
    "#The choice of algorithm isn't that important as long as it is skillful and consistent\n",
    "#To keep things simple, we'll use Univariate Selection\n",
    "#Univariate selection selects features that have the strongest relationship with the output variable\n",
    "#In this case, we can pretty easily use sckit learn's SelectKBest Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = data.drop(['m_rtg', 'f_rtg', 'label', 'i/g'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = m_data[m_data['sp_rtg'] != '-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find top 4 features\n",
    "test = SelectKBest(score_func=f_classif, k=5)\n",
    "fit = test.fit(m_data.iloc[:,2:-1],m_data.iloc[:,-1])\n",
    "scores = pd.DataFrame(fit.scores_, index=m_data.iloc[:,2:-1].columns)\n",
    "features = fit.transform(m_data.iloc[:,2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ebitda/net_sales</th>\n",
       "      <td>4.265572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gm</th>\n",
       "      <td>5.493388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_debt/e</th>\n",
       "      <td>1.784069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>11.548956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roe</th>\n",
       "      <td>19.380237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roa</th>\n",
       "      <td>11.798887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liabilities</th>\n",
       "      <td>25.030727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_interest_coverage</th>\n",
       "      <td>27.692001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfo/debt</th>\n",
       "      <td>4.175923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfo</th>\n",
       "      <td>24.725785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_debt/ebitda</th>\n",
       "      <td>1.444028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt/ebitda</th>\n",
       "      <td>1.435007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>st_borrowing</th>\n",
       "      <td>2.955496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mc</th>\n",
       "      <td>114.836355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt_borrowing</th>\n",
       "      <td>6.543044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_debt</th>\n",
       "      <td>5.161945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "ebitda/net_sales         4.265572\n",
       "gm                       5.493388\n",
       "net_debt/e               1.784069\n",
       "mv                      11.548956\n",
       "roe                     19.380237\n",
       "roa                     11.798887\n",
       "liabilities             25.030727\n",
       "net_interest_coverage   27.692001\n",
       "cfo/debt                 4.175923\n",
       "cfo                     24.725785\n",
       "net_debt/ebitda          1.444028\n",
       "debt/ebitda              1.435007\n",
       "st_borrowing             2.955496\n",
       "mc                     114.836355\n",
       "lt_borrowing             6.543044\n",
       "net_debt                 5.161945"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data = m_data.drop(['ebitda/net_sales', 'gm', 'net_debt/e', 'mv', 'roa', 'cfo/debt', 'debt/ebitda', 'net_debt/e', 'st_borrowing', 'lt_borrowing'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'A+', 'A-', 'AA', 'AA+', 'AA-', 'AAA', 'B', 'B+', 'B-', 'BB',\n",
       "       'BB+', 'BB-', 'BBB', 'BBB+', 'BBB-', 'CC', 'CCC', 'CCC+', 'CCC-', 'D',\n",
       "       'SD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a one-hot-encoded representation of s&p ratings\n",
    "sp_labels = pd.get_dummies(multi_data['sp_rtg'])\n",
    "sp_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2idx = {\n",
    "    'A+':0,\n",
    "    'A':1,\n",
    "    'A-':2,\n",
    "    'AA+':3,\n",
    "    'AA':4,\n",
    "    'AA-':5,\n",
    "    'AAA':6,\n",
    "    'B+':7,\n",
    "    'B':8,\n",
    "    'B-':9,\n",
    "    'BB+':10,\n",
    "    'BB':11,\n",
    "    'BB-':12,\n",
    "    'BBB+':21,\n",
    "    'BBB':13,\n",
    "    'BBB-':14,\n",
    "    'CC':15,\n",
    "    'CCC+':16,\n",
    "    'CCC':17,\n",
    "    'CCC-':18,\n",
    "    'D':19,\n",
    "    'SD':20\n",
    "}\n",
    "idx2class = {v: k for k, v in class2idx.items()}\n",
    "multi_data['sp_rtg'].replace(class2idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_labels=multi_data['sp_rtg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data = multi_data.drop(['sp_rtg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_data = multi_data.iloc[:,2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roe</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>net_interest_coverage</th>\n",
       "      <th>cfo</th>\n",
       "      <th>net_debt/ebitda</th>\n",
       "      <th>mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.47</td>\n",
       "      <td>351400000</td>\n",
       "      <td>50.4</td>\n",
       "      <td>113570000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.60923e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.316889</td>\n",
       "      <td>645840000</td>\n",
       "      <td>43.69</td>\n",
       "      <td>431270000</td>\n",
       "      <td>16.1444</td>\n",
       "      <td>1040000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.670909</td>\n",
       "      <td>1640000000</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-407000000</td>\n",
       "      <td>3.81818</td>\n",
       "      <td>140030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.62101e+09</td>\n",
       "      <td>3.73664</td>\n",
       "      <td>89990000</td>\n",
       "      <td>0</td>\n",
       "      <td>347510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0308772</td>\n",
       "      <td>222540000</td>\n",
       "      <td>7.87</td>\n",
       "      <td>787780000</td>\n",
       "      <td>1</td>\n",
       "      <td>1720000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>-0.708421</td>\n",
       "      <td>4.32593e+08</td>\n",
       "      <td>-0.300263</td>\n",
       "      <td>1.49124e+08</td>\n",
       "      <td>8.68421</td>\n",
       "      <td>6.05584e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>0.0194231</td>\n",
       "      <td>3.70428e+09</td>\n",
       "      <td>3.55029</td>\n",
       "      <td>1.16786e+09</td>\n",
       "      <td>2.55769</td>\n",
       "      <td>1930000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0.0287143</td>\n",
       "      <td>2.62101e+09</td>\n",
       "      <td>3.73664</td>\n",
       "      <td>1.08829e+09</td>\n",
       "      <td>3.40714</td>\n",
       "      <td>1.08925e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>-0.670909</td>\n",
       "      <td>351670000</td>\n",
       "      <td>0.520909</td>\n",
       "      <td>4.96609e+07</td>\n",
       "      <td>3.81818</td>\n",
       "      <td>54140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>-0.00794118</td>\n",
       "      <td>1.32312e+09</td>\n",
       "      <td>1.40912</td>\n",
       "      <td>5.98989e+08</td>\n",
       "      <td>3.11765</td>\n",
       "      <td>5.35642e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             roe  liabilities net_interest_coverage          cfo  \\\n",
       "0           2.47    351400000                  50.4    113570000   \n",
       "1      -0.316889    645840000                 43.69    431270000   \n",
       "2      -0.670909   1640000000                  11.1   -407000000   \n",
       "3           1.58  2.62101e+09               3.73664     89990000   \n",
       "4     -0.0308772    222540000                  7.87    787780000   \n",
       "...          ...          ...                   ...          ...   \n",
       "1289   -0.708421  4.32593e+08             -0.300263  1.49124e+08   \n",
       "1290   0.0194231  3.70428e+09               3.55029  1.16786e+09   \n",
       "1291   0.0287143  2.62101e+09               3.73664  1.08829e+09   \n",
       "1292   -0.670909    351670000              0.520909  4.96609e+07   \n",
       "1293 -0.00794118  1.32312e+09               1.40912  5.98989e+08   \n",
       "\n",
       "     net_debt/ebitda           mc  \n",
       "0                  0  2.60923e+10  \n",
       "1            16.1444   1040000000  \n",
       "2            3.81818    140030000  \n",
       "3                  0    347510000  \n",
       "4                  1   1720000000  \n",
       "...              ...          ...  \n",
       "1289         8.68421  6.05584e+08  \n",
       "1290         2.55769   1930000000  \n",
       "1291         3.40714  1.08925e+10  \n",
       "1292         3.81818     54140000  \n",
       "1293         3.11765  5.35642e+09  \n",
       "\n",
       "[1284 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "model=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model.fit_transform(multi_data)\n",
    "Y = np.array(sp_labels)\n",
    "dtype=torch.float\n",
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(X)\n",
    "target = torch.from_numpy(Y)\n",
    "data,target=data.type(torch.FloatTensor),target.type(torch.LongTensor)\n",
    "target=target.view(-1)\n",
    "data_length,data_width=data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:syft.workers.base:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker secure_worker already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:syft.workers.base:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:secure_worker #objects:46>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "bob.add_workers([alice, secure_worker])\n",
    "alice.add_workers([bob, secure_worker])\n",
    "secure_worker.add_workers([alice, bob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Data\n",
    "bobs_data = data[0:int(data_length/2)].send(bob)\n",
    "bobs_target = target[0:int(data_length/2)].send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alices_data = data[int(data_length/2):].send(alice)\n",
    "alices_target = target[int(data_length/2):].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0007\n",
    "NUM_FEATURES = 6\n",
    "NUM_CLASSES = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(torch.nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_feature, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (fc1): Linear(in_features=6, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=22, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "l = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.8220) Alice:tensor(0.6484)\n",
      "Bob:tensor(0.7057) Alice:tensor(0.5315)\n",
      "Bob:tensor(0.5467) Alice:tensor(0.3993)\n",
      "Bob:tensor(0.4298) Alice:tensor(0.3529)\n",
      "Bob:tensor(0.4863) Alice:tensor(0.3325)\n",
      "Bob:tensor(0.4574) Alice:tensor(0.3056)\n",
      "Bob:tensor(0.4074) Alice:tensor(0.3481)\n",
      "Bob:tensor(0.3518) Alice:tensor(0.2987)\n",
      "Bob:tensor(0.3652) Alice:tensor(0.2641)\n",
      "Bob:tensor(0.3630) Alice:tensor(0.2898)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "worker_iters = 200\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "    \n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.Adam(params=bobs_model.parameters(),lr=0.01)\n",
    "    alices_opt = optim.Adam(params=alices_model.parameters(),lr=0.01)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "        bobs_pred = bobs_model.forward(bobs_data)\n",
    "        bobs_loss = loss(bobs_pred,bobs_target)\n",
    "        bobs_loss.backward()        \n",
    "        bobs_opt.step()\n",
    "        bobs_loss = bobs_loss.get().data\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "        alices_pred = alices_model.forward(alices_data)\n",
    "        alices_loss = loss(alices_pred,alices_target)\n",
    "        alices_loss.backward()\n",
    "        alices_opt.step()\n",
    "        alices_loss = alices_loss.get().data\n",
    "\n",
    "    \n",
    "    alices_model.move(secure_worker)\n",
    "    bobs_model.move(secure_worker)\n",
    "    with torch.no_grad():\n",
    "        model.fc1.weight.set_(((alices_model.fc1.weight.data + bobs_model.fc1.weight.data) / 2).get())\n",
    "        model.fc1.bias.set_(((alices_model.fc1.bias.data + bobs_model.fc1.bias.data) / 2).get())\n",
    "        model.fc2.weight.set_(((alices_model.fc2.weight.data + bobs_model.fc2.weight.data) / 2).get())\n",
    "        model.fc2.bias.set_(((alices_model.fc2.bias.data + bobs_model.fc2.bias.data) / 2).get())\n",
    "        model.fc3.weight.set_(((alices_model.fc3.weight.data + bobs_model.fc3.weight.data) / 2).get())\n",
    "        model.fc3.bias.set_(((alices_model.fc3.bias.data + bobs_model.fc3.bias.data) / 2).get())\n",
    "        model.fc4.weight.set_(((alices_model.fc4.weight.data + bobs_model.fc4.weight.data) / 2).get())\n",
    "        model.fc4.bias.set_(((alices_model.fc4.bias.data + bobs_model.fc4.bias.data) / 2).get())\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
